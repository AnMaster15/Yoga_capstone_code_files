{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d2fa1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1edc1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, target_col='stress_score_weighted'):\n",
    "    \"\"\"Load and prepare data from a CSV file with improved error handling\"\"\"\n",
    "    # Load data\n",
    "    try:\n",
    "        # Try to read CSV with pandas, which will handle the header row correctly\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded data with shape: {df.shape}\")\n",
    "        \n",
    "        # Print first few rows to help diagnose issues\n",
    "        print(\"\\nFirst 5 rows of data:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # Print column names to help identify issues\n",
    "        print(\"\\nColumn names:\")\n",
    "        print(df.columns.tolist())\n",
    "        \n",
    "        # Check for the target column\n",
    "        if target_col not in df.columns:\n",
    "            # If target column not found, check if there's a similar column\n",
    "            possible_targets = [col for col in df.columns if 'stress' in col.lower()]\n",
    "            if possible_targets:\n",
    "                print(f\"\\nTarget column '{target_col}' not found, but found these possible stress-related columns:\")\n",
    "                print(possible_targets)\n",
    "                target_col = possible_targets[0]  # Use the first match\n",
    "                print(f\"Using '{target_col}' as the target column\")\n",
    "            else:\n",
    "                raise ValueError(f\"Target column '{target_col}' not found in dataset and no stress-related columns found\")\n",
    "        \n",
    "        # Check for non-numeric columns\n",
    "        non_numeric_cols = []\n",
    "        for col in df.columns:\n",
    "            try:\n",
    "                pd.to_numeric(df[col])\n",
    "            except:\n",
    "                non_numeric_cols.append(col)\n",
    "        \n",
    "        if non_numeric_cols:\n",
    "            print(f\"\\nWarning: Found non-numeric columns: {non_numeric_cols}\")\n",
    "            print(\"These columns will be dropped for modeling\")\n",
    "            \n",
    "            # Drop non-numeric columns except the target (we'll handle that separately)\n",
    "            for col in non_numeric_cols:\n",
    "                if col != target_col:\n",
    "                    df = df.drop(columns=[col])\n",
    "        \n",
    "        # Handle the target column\n",
    "        try:\n",
    "            # Try to convert target to numeric\n",
    "            df[target_col] = pd.to_numeric(df[target_col])\n",
    "        except:\n",
    "            print(f\"\\nError: Target column '{target_col}' contains non-numeric values\")\n",
    "            print(\"Sample values from target column:\")\n",
    "            print(df[target_col].head(10).tolist())\n",
    "            raise ValueError(f\"Target column '{target_col}' must be numeric\")\n",
    "        \n",
    "        # Extract target variable and features\n",
    "        X = df.drop(columns=[target_col])\n",
    "        y = df[target_col]\n",
    "        \n",
    "        # Convert all remaining columns to numeric (just to be safe)\n",
    "        for col in X.columns:\n",
    "            X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "        \n",
    "        # Handle any NaN values created by coercion\n",
    "        X = X.fillna(X.mean())\n",
    "        \n",
    "        print(f\"\\nFeatures shape after preprocessing: {X.shape}\")\n",
    "        print(f\"Target shape: {y.shape}\")\n",
    "        \n",
    "        return X, y\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28315023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, y, test_size=0.2, scaler_type='standard', select_k_features=None):\n",
    "    \"\"\"Preprocess the data: split, scale, and optionally select features\"\"\"\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Scale features\n",
    "    if scaler_type == 'robust':\n",
    "        scaler = RobustScaler()  # Less influenced by outliers\n",
    "    else:\n",
    "        scaler = StandardScaler()  # Standard z-score normalization\n",
    "        \n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Optional feature selection\n",
    "    feature_selector = None\n",
    "    if select_k_features is not None and select_k_features < X.shape[1]:\n",
    "        feature_selector = SelectKBest(f_regression, k=select_k_features)\n",
    "        X_train_scaled = feature_selector.fit_transform(X_train_scaled, y_train)\n",
    "        X_test_scaled = feature_selector.transform(X_test_scaled)\n",
    "        \n",
    "        # Get selected feature names\n",
    "        selected_indices = feature_selector.get_support(indices=True)\n",
    "        selected_features = X.columns[selected_indices]\n",
    "        print(f\"Selected top {select_k_features} features: {selected_features.tolist()}\")\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler, feature_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "458c2c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim, architecture=[128, 64, 32], dropout_rate=0.3,\n",
    "               learning_rate=0.001, activation='leaky_relu'):\n",
    "    \"\"\"Build a neural network model for stress prediction\"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input layer\n",
    "    if activation == 'leaky_relu':\n",
    "        model.add(Dense(architecture[0], input_dim=input_dim))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "    else:\n",
    "        model.add(Dense(architecture[0], input_dim=input_dim, activation=activation))\n",
    "        \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Hidden layers\n",
    "    for units in architecture[1:]:\n",
    "        if activation == 'leaky_relu':\n",
    "            model.add(Dense(units))\n",
    "            model.add(LeakyReLU(alpha=0.1))\n",
    "        else:\n",
    "            model.add(Dense(units, activation=activation))\n",
    "            \n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Output layer for regression\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    # Display model summary\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08fae107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, epochs=200, batch_size=32, validation_split=0.2,\n",
    "               patience=25, verbose=1, model_path=None):\n",
    "    \"\"\"Train the model with early stopping and learning rate reduction\"\"\"\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6)\n",
    "    ]\n",
    "    \n",
    "    # Add model checkpoint if path provided\n",
    "    if model_path:\n",
    "        if not os.path.exists(model_path):\n",
    "            os.makedirs(model_path)\n",
    "        callbacks.append(ModelCheckpoint(\n",
    "            f'{model_path}/best_model.h5', save_best_only=True, monitor='val_loss'\n",
    "        ))\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=callbacks,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "450da7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate the model on test data\"\"\"\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    metrics = {\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R²': r2\n",
    "    }\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "        \n",
    "    # Plot predictions\n",
    "    plot_predictions(y_test, y_pred)\n",
    "        \n",
    "    return metrics, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6a2b837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(X, y):\n",
    "    \"\"\"Calculate feature importance using correlation with target\"\"\"\n",
    "    # Create a dataframe with features and target\n",
    "    df = pd.concat([X, pd.Series(y, name='target')], axis=1)\n",
    "    \n",
    "    # Calculate correlation with target\n",
    "    correlations = df.corr()['target'].drop('target').abs().sort_values(ascending=False)\n",
    "    \n",
    "    # Display top correlations\n",
    "    print(\"\\nTop feature correlations with stress score:\")\n",
    "    print(correlations.head(10))\n",
    "    \n",
    "    # Plot top 15 correlations\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_15 = correlations.head(15)\n",
    "    sns.barplot(x=top_15.values, y=top_15.index)\n",
    "    plt.title('Top 15 Features by Correlation with Stress Score')\n",
    "    plt.xlabel('Absolute Correlation')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "948ad21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(X, y, n_splits=5, epochs=100, batch_size=32):\n",
    "    \"\"\"Perform k-fold cross-validation\"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    fold_metrics = []\n",
    "    \n",
    "    print(f\"\\nPerforming {n_splits}-fold cross-validation:\")\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\nFold {fold+1}/{n_splits}\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Preprocess\n",
    "        scaler = RobustScaler()  # Use RobustScaler for cross-validation\n",
    "        X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_scaled = scaler.transform(X_val_fold)\n",
    "        \n",
    "        # Build model for this fold\n",
    "        input_dim = X_train_scaled.shape[1]\n",
    "        model = build_model(input_dim)\n",
    "        \n",
    "        # Training with early stopping\n",
    "        callbacks = [EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)]\n",
    "        model.fit(\n",
    "            X_train_scaled, y_train_fold,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val_scaled, y_val_fold),\n",
    "            callbacks=callbacks,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = model.predict(X_val_scaled).flatten()\n",
    "        metrics = {\n",
    "            'MSE': mean_squared_error(y_val_fold, y_pred),\n",
    "            'RMSE': np.sqrt(mean_squared_error(y_val_fold, y_pred)),\n",
    "            'MAE': mean_absolute_error(y_val_fold, y_pred),\n",
    "            'R²': r2_score(y_val_fold, y_pred)\n",
    "        }\n",
    "        fold_metrics.append(metrics)\n",
    "        print(f\"Fold {fold+1} metrics: MSE={metrics['MSE']:.4f}, R²={metrics['R²']:.4f}\")\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {\n",
    "        metric: np.mean([fold[metric] for fold in fold_metrics])\n",
    "        for metric in fold_metrics[0].keys()\n",
    "    }\n",
    "    \n",
    "    std_metrics = {\n",
    "        metric: np.std([fold[metric] for fold in fold_metrics])\n",
    "        for metric in fold_metrics[0].keys()\n",
    "    }\n",
    "    \n",
    "    print(\"\\nCross-validation results:\")\n",
    "    for metric in avg_metrics.keys():\n",
    "        print(f\"{metric}: {avg_metrics[metric]:.4f} ± {std_metrics[metric]:.4f}\")\n",
    "        \n",
    "    # Plot cross-validation results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    metrics_to_plot = ['MSE', 'MAE', 'R²']\n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        values = [fold[metric] for fold in fold_metrics]\n",
    "        plt.bar(range(1, n_splits+1), values)\n",
    "        plt.title(f'{metric} by Fold')\n",
    "        plt.xlabel('Fold')\n",
    "        plt.ylabel(metric)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "        \n",
    "    return {\n",
    "        'fold_metrics': fold_metrics,\n",
    "        'avg_metrics': avg_metrics,\n",
    "        'std_metrics': std_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e7f98f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, scaler, feature_selector, feature_names, model_path='stress_model'):\n",
    "    \"\"\"Save the model, scaler, and feature selector to disk\"\"\"\n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "        \n",
    "    # Save model\n",
    "    model.save(f'{model_path}/model.h5')\n",
    "    \n",
    "    # Save scaler\n",
    "    if scaler is not None:\n",
    "        joblib.dump(scaler, f'{model_path}/scaler.pkl')\n",
    "        \n",
    "    # Save feature selector\n",
    "    if feature_selector is not None:\n",
    "        joblib.dump(feature_selector, f'{model_path}/feature_selector.pkl')\n",
    "        \n",
    "    # Save feature names\n",
    "    if feature_names is not None:\n",
    "        pd.Series(feature_names).to_csv(f'{model_path}/feature_names.csv', index=False)\n",
    "        \n",
    "    print(f\"Model and preprocessors saved to {model_path}/\")\n",
    "    \n",
    "    return f\"Model saved to {model_path}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "90883f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_model(model_path='stress_model'):\n",
    "    \"\"\"Load the model, scaler, and feature selector from disk\"\"\"\n",
    "    try:\n",
    "        # Load model\n",
    "        model = load_model(f'{model_path}/model.h5')\n",
    "        print(\"Model loaded successfully\")\n",
    "        \n",
    "        # Load scaler\n",
    "        scaler = None\n",
    "        scaler_path = f'{model_path}/scaler.pkl'\n",
    "        if os.path.exists(scaler_path):\n",
    "            scaler = joblib.load(scaler_path)\n",
    "            print(\"Scaler loaded successfully\")\n",
    "            \n",
    "        # Load feature selector\n",
    "        feature_selector = None\n",
    "        selector_path = f'{model_path}/feature_selector.pkl'\n",
    "        if os.path.exists(selector_path):\n",
    "            feature_selector = joblib.load(selector_path)\n",
    "            print(\"Feature selector loaded successfully\")\n",
    "            \n",
    "        # Load feature names\n",
    "        feature_names = None\n",
    "        feature_names_path = f'{model_path}/feature_names.csv'\n",
    "        if os.path.exists(feature_names_path):\n",
    "            feature_names = pd.read_csv(feature_names_path).iloc[:, 0].values\n",
    "            print(f\"Loaded {len(feature_names)} feature names\")\n",
    "            \n",
    "        return model, scaler, feature_selector, feature_names\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9f703bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stress(model, new_data, scaler=None, feature_selector=None, feature_names=None):\n",
    "    \"\"\"Make stress predictions on new data\"\"\"\n",
    "    # Convert to DataFrame if array\n",
    "    if not isinstance(new_data, pd.DataFrame) and feature_names is not None:\n",
    "        new_data = pd.DataFrame(new_data, columns=feature_names)\n",
    "        \n",
    "    # Ensure we have the right features\n",
    "    if isinstance(new_data, pd.DataFrame) and feature_names is not None:\n",
    "        missing_features = set(feature_names) - set(new_data.columns)\n",
    "        if missing_features:\n",
    "            print(f\"Warning: Missing features in input data: {missing_features}\")\n",
    "            return None\n",
    "            \n",
    "        # Reorder columns to match training data\n",
    "        new_data = new_data[feature_names]\n",
    "        \n",
    "    # Preprocess data\n",
    "    if scaler is not None:\n",
    "        new_data = scaler.transform(new_data)\n",
    "        \n",
    "    if feature_selector is not None:\n",
    "        new_data = feature_selector.transform(new_data)\n",
    "        \n",
    "    # Make predictions\n",
    "    predictions = model.predict(new_data).flatten()\n",
    "    \n",
    "    # Display summary statistics of predictions\n",
    "    print(\"\\nPrediction Results:\")\n",
    "    print(f\"Mean predicted stress: {predictions.mean():.2f}\")\n",
    "    print(f\"Min predicted stress: {predictions.min():.2f}\")\n",
    "    print(f\"Max predicted stress: {predictions.max():.2f}\")\n",
    "    \n",
    "    # Plot histogram of predictions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(predictions, bins=20, alpha=0.7, color='blue')\n",
    "    plt.title('Distribution of Predicted Stress Scores')\n",
    "    plt.xlabel('Predicted Stress Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "52fa1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Plot the training history\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot MAE\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['mae'], label='Training MAE')\n",
    "    plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "    plt.title('Mean Absolute Error')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4fd57d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(X, y, param_grid):\n",
    "    \"\"\"Simple hyperparameter tuning for the neural network model\"\"\"\n",
    "    # Split data once for consistent evaluation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Scale data\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    # Initialize results\n",
    "    results = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    # Create parameter combinations\n",
    "    def create_param_combinations(param_grid):\n",
    "        keys = param_grid.keys()\n",
    "        combinations = []\n",
    "        \n",
    "        # Recursive function to generate combinations\n",
    "        def recurse(combination, keys_list):\n",
    "            if not keys_list:\n",
    "                combinations.append(combination.copy())\n",
    "                return\n",
    "            \n",
    "            current_key = keys_list[0]\n",
    "            for value in param_grid[current_key]:\n",
    "                combination[current_key] = value\n",
    "                recurse(combination, keys_list[1:])\n",
    "        \n",
    "        recurse({}, list(keys))\n",
    "        return combinations\n",
    "    \n",
    "    # Get all parameter combinations\n",
    "    param_combinations = create_param_combinations(param_grid)\n",
    "    print(f\"Testing {len(param_combinations)} hyperparameter combinations...\")\n",
    "    \n",
    "    for i, params in enumerate(param_combinations):\n",
    "        print(f\"\\nTesting combination {i+1}/{len(param_combinations)}: {params}\")\n",
    "        \n",
    "        # Build model with current parameters\n",
    "        input_dim = X_train_scaled.shape[1]\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Input layer\n",
    "        if params.get('activation', 'relu') == 'leaky_relu':\n",
    "            model.add(Dense(params['first_layer'], input_dim=input_dim))\n",
    "            model.add(LeakyReLU(alpha=0.1))\n",
    "        else:\n",
    "            model.add(Dense(params['first_layer'], input_dim=input_dim, \n",
    "                           activation=params.get('activation', 'relu')))\n",
    "            \n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(params.get('dropout_rate', 0.3)))\n",
    "        \n",
    "        # Hidden layers (if specified)\n",
    "        if 'second_layer' in params and params['second_layer'] > 0:\n",
    "            if params.get('activation', 'relu') == 'leaky_relu':\n",
    "                model.add(Dense(params['second_layer']))\n",
    "                model.add(LeakyReLU(alpha=0.1))\n",
    "            else:\n",
    "                model.add(Dense(params['second_layer'], \n",
    "                               activation=params.get('activation', 'relu')))\n",
    "                \n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(params.get('dropout_rate', 0.3)))\n",
    "        \n",
    "        # Output layer\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        \n",
    "        # Compile model\n",
    "        optimizer = Adam(learning_rate=params.get('learning_rate', 0.001))\n",
    "        model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "        \n",
    "        # Train with early stopping\n",
    "        callbacks = [EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)]\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=100,  # Max epochs\n",
    "            batch_size=params.get('batch_size', 32),\n",
    "            validation_data=(X_val_scaled, y_val),\n",
    "            callbacks=callbacks,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_loss = model.evaluate(X_val_scaled, y_val, verbose=0)[0]\n",
    "        y_pred = model.predict(X_val_scaled).flatten()\n",
    "        val_r2 = r2_score(y_val, y_pred)\n",
    "        \n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val R²: {val_r2:.4f}\")\n",
    "        \n",
    "        # Save results\n",
    "        results.append({\n",
    "            'params': params,\n",
    "            'val_loss': val_loss,\n",
    "            'val_r2': val_r2,\n",
    "            'epochs_trained': len(history.history['loss'])\n",
    "        })\n",
    "        \n",
    "        # Check if this is best so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "            print(f\"New best model found!\")\n",
    "    \n",
    "    # Sort results by validation loss\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('val_loss')\n",
    "    \n",
    "    print(\"\\nTop 5 hyperparameter combinations:\")\n",
    "    print(results_df.head(5)[['params', 'val_loss', 'val_r2']])\n",
    "    \n",
    "    print(f\"\\nBest hyperparameters: {best_params}\")\n",
    "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "    \n",
    "    # Plot top combinations\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    top_5 = results_df.head(5)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(range(5), top_5['val_loss'])\n",
    "    plt.title('Validation Loss - Top 5')\n",
    "    plt.xlabel('Combination Rank')\n",
    "    plt.ylabel('MSE')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(range(5), top_5['val_r2'])\n",
    "    plt.title('Validation R² - Top 5')\n",
    "    plt.xlabel('Combination Rank')\n",
    "    plt.ylabel('R²')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return best_model, best_params, results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a3adbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_workflow(file_path, target_col='stress_score_weighted'):\n",
    "    \"\"\"Example of how to use the functions in sequence\"\"\"\n",
    "    # 1. Load data\n",
    "    X, y = load_data(file_path, target_col=target_col)\n",
    "    \n",
    "    # 2. Preprocess data\n",
    "    X_train, X_test, y_train, y_test, scaler, feature_selector = preprocess_data(\n",
    "        X, y, scaler_type='robust'\n",
    "    )\n",
    "    \n",
    "    # 3. Build model\n",
    "    model = build_model(input_dim=X_train.shape[1])\n",
    "    \n",
    "    # 4. Train model\n",
    "    trained_model, history = train_model(model, X_train, y_train)\n",
    "    \n",
    "    # 5. Evaluate model\n",
    "    metrics, predictions = evaluate_model(trained_model, X_test, y_test)\n",
    "    \n",
    "    # 6. Save model if needed\n",
    "    save_model(trained_model, scaler, feature_selector, X.columns.tolist())\n",
    "    \n",
    "    return trained_model, metrics, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffc11192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data file from command line argument: --f=/Users/anchitmehra/Library/Jupyter/runtime/kernel-v3804f025fc011677f1d0d131d8b0027e821468dc9.json\n",
      "Starting stress prediction analysis...\n",
      "Error loading data: [Errno 2] No such file or directory: '--f=/Users/anchitmehra/Library/Jupyter/runtime/kernel-v3804f025fc011677f1d0d131d8b0027e821468dc9.json'\n",
      "\n",
      "ERROR: Data file not found. Please update the 'data_file' variable with the correct path.\n",
      "You can also try creating a sample dataset for testing.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Specify the path to your dataset file\n",
    "    data_file = \"Final_merged_dataset_with_weighted_stress.csv\"  # Default to sample data\n",
    "    \n",
    "    # If you have a specific column for stress scores, specify it here\n",
    "    target_column = \"stress_score_weighted\"\n",
    "    \n",
    "    # Check if the user provided a CSV file as argument\n",
    "    import sys\n",
    "    if len(sys.argv) > 1:\n",
    "        data_file = sys.argv[1]\n",
    "        print(f\"Using data file from command line argument: {data_file}\")\n",
    "    \n",
    "    try:\n",
    "        # Run the full workflow\n",
    "        print(\"Starting stress prediction analysis...\")\n",
    "        model, metrics, predictions = example_workflow(data_file, target_column)\n",
    "        print(\"\\nAnalysis completed successfully!\")\n",
    "        \n",
    "        # Print final performance metrics\n",
    "        print(\"\\nFinal model performance:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(\"\\nERROR: Data file not found. Please update the 'data_file' variable with the correct path.\")\n",
    "        print(\"You can also try creating a sample dataset for testing.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during analysis: {e}\")\n",
    "        \n",
    "        # Provide options for debugging\n",
    "        print(\"\\nDebugging suggestions:\")\n",
    "        print(\"1. Check if your data file exists and is accessible\")\n",
    "        print(\"2. Verify that your data contains the expected target column\")\n",
    "        print(\"3. Inspect the first few rows of your data to ensure it's formatted correctly\")\n",
    "        print(\"4. Check for missing values or invalid data types in your dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d384c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
