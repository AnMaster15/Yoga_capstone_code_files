{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WESAD\n",
    "###  A Multimodal Dataset for Wearable Stress and Affect Detection\n",
    "\n",
    "##### Matthew Johnson, 2019\n",
    "\n",
    "===============================================================================================================\n",
    "\n",
    "\n",
    "### Dataset Information [1]:\n",
    "Data Set Information:\n",
    "\n",
    "WESAD is a publicly available dataset for wearable stress and affect detection. This multimodal dataset features physiological and motion data, recorded from both a wrist- and a chest-worn device, of 15 subjects during a lab study. The following sensor modalities are included: blood volume pulse, electrocardiogram, electrodermal activity, electromyogram, respiration, body temperature, and three-axis acceleration. Moreover, the dataset bridges the gap between previous lab studies on stress and emotions, by containing three different affective states (neutral, stress, amusement). In addition, self-reports of the subjects, which were obtained using several established questionnaires, are contained in the dataset. Details can be found in the dataset's readme-file, as well as in [1].\n",
    "\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "Raw sensor data was recorded with two devices: a chest-worn device (RespiBAN) and a wrist-worn device (Empatica E4). \n",
    "The RespiBAN device provides the following sensor data: electrocardiogram (ECG), electrodermal activity (EDA), electromyogram (EMG), respiration, body temperature, and three-axis acceleration. All signals are sampled at 700 Hz. \n",
    "The Empatica E4 device provides the following sensor data: blood volume pulse (BVP, 64 Hz), electrodermal activity (EDA, 4 Hz), body temperature (4 Hz), and three-axis acceleration (32 Hz). \n",
    "\n",
    "The dataset's readme-file contains all further details with respect to the dataset structure, data format (RespiBAN device, Empatica E4 device, synchronised data), study protocol, and the self-report questionnaires.\n",
    "\n",
    "\n",
    "- https://archive.ics.uci.edu/ml/datasets/WESAD+%28Wearable+Stress+and+Affect+Detection%29\n",
    "\n",
    "\n",
    "\n",
    "### Classes\n",
    "\n",
    "**Baseline condition**: 20 minute period of standing/sitting reading magazines.<br>\n",
    "**Amusement condition**: During the amusement condition, the\n",
    "subjects watched a set of eleven funny video clips.<br>\n",
    "**Stress condition**: Trier Social Stress Test (TSST), consisting of public speaking and mental arithmetic.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "------------\n",
    "   \n",
    "#### References\n",
    "\n",
    "[1] Schmidt, Philip & Reiss, Attila & Duerichen, Robert & Marberger, Claus & Van Laerhoven, Kristof. (2018). Introducing WESAD, a Multimodal Dataset for Wearable Stress and Affect Detection. 400-408. 10.1145/3242969.3242985.  https://dl.acm.org/citation.cfm?doid=3242969.3242985\n",
    "\n",
    "[2] A Greco, G Valenza, A Lanata, EP Scilingo, and L Citi\n",
    "\"cvxEDA: a Convex Optimization Approach to Electrodermal Activity Processing\"\n",
    "IEEE Transactions on Biomedical Engineering, 2015\n",
    "DOI: 10.1109/TBME.2015.2474131\n",
    "https://github.com/lciti/cvxEDA\n",
    "\n",
    "[3] J. Choi, B. Ahmed, and R. Gutierrez-Osuna. 2012. Development and evaluation\n",
    "of an ambulatory stress monitor based on wearable sensors. IEEE Transactions\n",
    "on Information Technology in Biomedicine 16, 2 (2012).  \n",
    "    http://research.cs.tamu.edu/prism/publications/choi2011ambulatoryStressMonitor.pdf\n",
    "    \n",
    "[6] J. Healey and **R. Picard.** 2005. Detecting stress during real-world driving tasks\n",
    "using physiological sensors. IEEE Transactions on Intelligent Transportation\n",
    "Systems 6, 2 (2005), 156–166.  \n",
    "\n",
    "\n",
    "#### Useful Resources:\n",
    "- https://github.com/jaganjag/stress_affect_detection\n",
    "- https://github.com/arsen-movsesyan/springboard_WESAD\n",
    "- https://www.birmingham.ac.uk/Documents/college-les/psych/saal/guide-electrodermal-activity.pdf\n",
    "- http://research.cs.tamu.edu/prism/publications/choi2011ambulatoryStressMonitor.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " TODO: \n",
    "        - add early stopping?\n",
    "        - maybe change to binary classification (stress, not-stress)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.0.1\n",
      "Uninstalling torch-2.0.1:\n",
      "  Successfully uninstalled torch-2.0.1\n",
      "Found existing installation: torchvision 0.15.2\n",
      "Uninstalling torchvision-0.15.2:\n",
      "  Successfully uninstalled torchvision-0.15.2\n",
      "Found existing installation: torchaudio 2.0.2\n",
      "Uninstalling torchaudio-2.0.2:\n",
      "  Successfully uninstalled torchaudio-2.0.2\n",
      "Files removed: 48 (63.7 MB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp311-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.21.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/anchitmehra/Library/Python/3.11/lib/python/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.11/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/homebrew/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from torchvision) (2.2.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/lib/python3.11/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.6.0-cp311-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.21.0-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.6.0-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.6.0 torchaudio-2.6.0 torchvision-0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio -y\n",
    "!pip cache purge\n",
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WESADDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe.drop('subject', axis=1)\n",
    "        self.labels = self.dataframe['label'].values\n",
    "        self.dataframe.drop('label', axis=1, inplace=True)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.dataframe.iloc[idx].values\n",
    "        y = self.labels[idx]\n",
    "        return torch.Tensor(x), y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "feats =   ['BVP_mean', 'BVP_std', 'BVP_min', 'BVP_max',\n",
    "           'EDA_phasic_mean', 'EDA_phasic_std', 'EDA_phasic_min', 'EDA_phasic_max', 'EDA_smna_mean',\n",
    "           'EDA_smna_std', 'EDA_smna_min', 'EDA_smna_max', 'EDA_tonic_mean',\n",
    "           'EDA_tonic_std', 'EDA_tonic_min', 'EDA_tonic_max', 'Resp_mean',\n",
    "           'Resp_std', 'Resp_min', 'Resp_max', 'TEMP_mean', 'TEMP_std', 'TEMP_min',\n",
    "           'TEMP_max', 'TEMP_slope', 'BVP_peak_freq', 'age', 'height',\n",
    "           'weight','subject', 'label']\n",
    "layer_1_dim = len(feats) -2\n",
    "print(layer_1_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(df, subject_id, train_batch_size=25, test_batch_size=5):\n",
    "    #df = pd.read_csv('data/m14_merged.csv', index_col=0)[feats]\n",
    "\n",
    "    train_df = df[ df['subject'] != subject_id].reset_index(drop=True)\n",
    "    test_df = df[ df['subject'] == subject_id].reset_index(drop=True)\n",
    "    \n",
    "    train_dset = WESADDataset(train_df)\n",
    "    test_dset = WESADDataset(test_df)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dset, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dset, batch_size=test_batch_size)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StressNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StressNet, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "                        nn.Linear(29, 128),\n",
    "                        #nn.Dropout(0.5),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(128, 256),\n",
    "                        #nn.Dropout(0.5),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(256, 2),\n",
    "                        #nn.Dropout(0.5),\n",
    "                        nn.LogSoftmax(dim=1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, validation_loader):\n",
    "    history = {'train_loss': {}, 'train_acc': {}, 'valid_loss': {}, 'valid_acc': {}}\n",
    "    #\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Train:   \n",
    "        total = 0\n",
    "        correct = 0\n",
    "        trainlosses = []\n",
    "\n",
    "        for batch_index, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            # Send to GPU (device)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images.float())\n",
    "\n",
    "            # Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            trainlosses.append(loss.item())\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, argmax = torch.max(outputs, 1)\n",
    "            correct += (labels == argmax).sum().item() #.mean()\n",
    "            total += len(labels)\n",
    "\n",
    "        history['train_loss'][epoch] = np.mean(trainlosses) \n",
    "        history['train_acc'][epoch] = correct/total \n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "\n",
    "                losses = []\n",
    "                total = 0\n",
    "                correct = 0\n",
    "\n",
    "                for images, labels in validation_loader:\n",
    "                    # \n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                    # Forward pass\n",
    "                    outputs = model(images.float())\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Compute accuracy\n",
    "                    _, argmax = torch.max(outputs, 1)\n",
    "                    correct += (labels == argmax).sum().item() #.mean()\n",
    "                    total += len(labels)\n",
    "\n",
    "                    losses.append(loss.item())\n",
    "                    \n",
    "                history['valid_acc'][epoch] = np.round(correct/total, 3)\n",
    "                history['valid_loss'][epoch] = np.mean(losses)\n",
    "\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {np.mean(losses):.4}, Acc: {correct/total:.2}')\n",
    "                \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, validation_loader):\n",
    "    print('Evaluating model...')\n",
    "    # Test\n",
    "    model.eval()\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    testlosses = []\n",
    "    correct_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch_index, (images, labels) in enumerate(validation_loader):\n",
    "            # Send to GPU (device)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images.float())\n",
    "\n",
    "            # Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            testlosses.append(loss.item())\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, argmax = torch.max(outputs, 1)\n",
    "            correct += (labels == argmax).sum().item() #.mean()\n",
    "            total += len(labels)\n",
    "\n",
    "            correct_labels.extend(labels)\n",
    "            predictions.extend(argmax)\n",
    "\n",
    "\n",
    "    test_loss = np.mean(testlosses)\n",
    "    accuracy = np.round(correct/total, 2)\n",
    "    print(f'Loss: {test_loss:.4}, Acc: {accuracy:.2}')\n",
    "    \n",
    "    y_true = [label.item() for label in correct_labels]\n",
    "    y_pred = [label.item() for label in predictions]\n",
    "\n",
    "    # TODO: return y true and y pred, make cm after ( use ytrue/ypred for classification report)\n",
    "    return y_true, y_pred, test_loss, accuracy\n",
    "    #return cm, test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>net_acc_mean</th>\n",
       "      <th>net_acc_std</th>\n",
       "      <th>net_acc_min</th>\n",
       "      <th>net_acc_max</th>\n",
       "      <th>EDA_phasic_mean</th>\n",
       "      <th>EDA_phasic_std</th>\n",
       "      <th>EDA_phasic_min</th>\n",
       "      <th>EDA_phasic_max</th>\n",
       "      <th>EDA_smna_mean</th>\n",
       "      <th>EDA_smna_std</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>gender_ female</th>\n",
       "      <th>gender_ male</th>\n",
       "      <th>coffee_today_YES</th>\n",
       "      <th>sport_today_YES</th>\n",
       "      <th>smoker_NO</th>\n",
       "      <th>smoker_YES</th>\n",
       "      <th>feel_ill_today_YES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.609529</td>\n",
       "      <td>0.141481</td>\n",
       "      <td>-358.13</td>\n",
       "      <td>554.77</td>\n",
       "      <td>0.609529</td>\n",
       "      <td>1.089131</td>\n",
       "      <td>-358.13</td>\n",
       "      <td>554.77</td>\n",
       "      <td>0.609529</td>\n",
       "      <td>1.952141</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.538008</td>\n",
       "      <td>0.091882</td>\n",
       "      <td>-392.28</td>\n",
       "      <td>438.16</td>\n",
       "      <td>0.538008</td>\n",
       "      <td>1.223623</td>\n",
       "      <td>-392.28</td>\n",
       "      <td>438.16</td>\n",
       "      <td>0.538008</td>\n",
       "      <td>2.854162</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.574784</td>\n",
       "      <td>0.102315</td>\n",
       "      <td>-240.61</td>\n",
       "      <td>209.89</td>\n",
       "      <td>0.574784</td>\n",
       "      <td>0.129121</td>\n",
       "      <td>-240.61</td>\n",
       "      <td>209.89</td>\n",
       "      <td>0.574784</td>\n",
       "      <td>0.245284</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.590880</td>\n",
       "      <td>0.046391</td>\n",
       "      <td>-289.26</td>\n",
       "      <td>145.36</td>\n",
       "      <td>0.590880</td>\n",
       "      <td>0.126564</td>\n",
       "      <td>-289.26</td>\n",
       "      <td>145.36</td>\n",
       "      <td>0.590880</td>\n",
       "      <td>0.201035</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.567452</td>\n",
       "      <td>0.034540</td>\n",
       "      <td>-197.37</td>\n",
       "      <td>194.12</td>\n",
       "      <td>0.567452</td>\n",
       "      <td>0.039667</td>\n",
       "      <td>-197.37</td>\n",
       "      <td>194.12</td>\n",
       "      <td>0.567452</td>\n",
       "      <td>0.115003</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   net_acc_mean  net_acc_std  net_acc_min  net_acc_max  EDA_phasic_mean  \\\n",
       "0      0.609529     0.141481      -358.13       554.77         0.609529   \n",
       "1      0.538008     0.091882      -392.28       438.16         0.538008   \n",
       "2      0.574784     0.102315      -240.61       209.89         0.574784   \n",
       "3      0.590880     0.046391      -289.26       145.36         0.590880   \n",
       "4      0.567452     0.034540      -197.37       194.12         0.567452   \n",
       "\n",
       "   EDA_phasic_std  EDA_phasic_min  EDA_phasic_max  EDA_smna_mean  \\\n",
       "0        1.089131         -358.13          554.77       0.609529   \n",
       "1        1.223623         -392.28          438.16       0.538008   \n",
       "2        0.129121         -240.61          209.89       0.574784   \n",
       "3        0.126564         -289.26          145.36       0.590880   \n",
       "4        0.039667         -197.37          194.12       0.567452   \n",
       "\n",
       "   EDA_smna_std  ...  age  height  weight  gender_ female  gender_ male  \\\n",
       "0      1.952141  ...   27     175      80           False          True   \n",
       "1      2.854162  ...   27     175      80           False          True   \n",
       "2      0.245284  ...   27     175      80           False          True   \n",
       "3      0.201035  ...   27     175      80           False          True   \n",
       "4      0.115003  ...   27     175      80           False          True   \n",
       "\n",
       "   coffee_today_YES  sport_today_YES  smoker_NO  smoker_YES  \\\n",
       "0             False            False       True       False   \n",
       "1             False            False       True       False   \n",
       "2             False            False       True       False   \n",
       "3             False            False       True       False   \n",
       "4             False            False       True       False   \n",
       "\n",
       "   feel_ill_today_YES  \n",
       "0               False  \n",
       "1               False  \n",
       "2               False  \n",
       "3               False  \n",
       "4               False  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/m14_merged.csv', index_col=0)\n",
    "subject_id_list = df['subject'].unique()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_label(label):\n",
    "    if label == 0 or label == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "df['label'] = df['label'].apply(change_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subject:  2\n",
      "Epoch [1/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [11/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [21/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [31/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [41/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [51/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [61/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [71/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [81/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [91/100], Loss: 0.0, Acc: 1.0\n",
      "Evaluating model...\n",
      "Loss: 0.0, Acc: 1.0\n",
      "\n",
      "Subject:  3\n",
      "Epoch [1/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [11/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [21/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [31/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [41/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [51/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [61/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [71/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [81/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [91/100], Loss: 0.0, Acc: 1.0\n",
      "Evaluating model...\n",
      "Loss: 0.0, Acc: 1.0\n",
      "\n",
      "Subject:  4\n",
      "Epoch [1/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [11/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [21/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [31/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [41/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [51/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [61/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [71/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [81/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [91/100], Loss: 0.0, Acc: 1.0\n",
      "Evaluating model...\n",
      "Loss: 0.0, Acc: 1.0\n",
      "\n",
      "Subject:  5\n",
      "Epoch [1/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [11/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [21/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [31/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [41/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [51/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [61/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [71/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [81/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [91/100], Loss: 0.0, Acc: 1.0\n",
      "Evaluating model...\n",
      "Loss: 0.0, Acc: 1.0\n",
      "\n",
      "Subject:  6\n",
      "Epoch [1/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [11/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [21/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [31/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [41/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [51/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [61/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [71/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [81/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [91/100], Loss: 0.0, Acc: 1.0\n",
      "Evaluating model...\n",
      "Loss: 0.0, Acc: 1.0\n",
      "\n",
      "Subject:  7\n",
      "Epoch [1/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [11/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [21/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [31/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [41/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [51/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [61/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [71/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [81/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [91/100], Loss: 0.0, Acc: 1.0\n",
      "Evaluating model...\n",
      "Loss: 0.0, Acc: 1.0\n",
      "\n",
      "Subject:  8\n",
      "Epoch [1/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [11/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [21/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [31/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [41/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [51/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [61/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [71/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [81/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [91/100], Loss: 0.0, Acc: 1.0\n",
      "Evaluating model...\n",
      "Loss: 0.0, Acc: 1.0\n",
      "\n",
      "Subject:  9\n",
      "Epoch [1/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [11/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [21/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [31/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [41/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [51/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [61/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [71/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [81/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [91/100], Loss: 0.0, Acc: 1.0\n",
      "Evaluating model...\n",
      "Loss: 0.0, Acc: 1.0\n",
      "\n",
      "Subject:  10\n",
      "Epoch [1/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [11/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [21/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [31/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [41/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [51/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [61/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [71/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [81/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [91/100], Loss: 0.0, Acc: 1.0\n",
      "Evaluating model...\n",
      "Loss: 0.0, Acc: 1.0\n",
      "\n",
      "Subject:  11\n",
      "Epoch [1/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [11/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [21/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [31/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [41/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [51/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [61/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [71/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [81/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [91/100], Loss: 0.0, Acc: 1.0\n",
      "Evaluating model...\n",
      "Loss: 0.0, Acc: 1.0\n",
      "\n",
      "Subject:  13\n",
      "Epoch [1/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [11/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [21/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [31/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [41/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [51/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [61/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [71/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [81/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [91/100], Loss: 0.0, Acc: 1.0\n",
      "Evaluating model...\n",
      "Loss: 0.0, Acc: 1.0\n",
      "\n",
      "Subject:  14\n",
      "Epoch [1/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [11/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [21/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [31/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [41/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [51/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [61/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [71/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [81/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [91/100], Loss: 0.0, Acc: 1.0\n",
      "Evaluating model...\n",
      "Loss: 0.0, Acc: 1.0\n",
      "\n",
      "Subject:  15\n",
      "Epoch [1/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [11/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [21/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [31/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [41/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [51/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [61/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [71/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [81/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [91/100], Loss: 0.0, Acc: 1.0\n",
      "Evaluating model...\n",
      "Loss: 0.0, Acc: 1.0\n",
      "\n",
      "Subject:  16\n",
      "Epoch [1/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [11/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [21/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [31/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [41/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [51/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [61/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [71/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [81/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [91/100], Loss: 0.0, Acc: 1.0\n",
      "Evaluating model...\n",
      "Loss: 0.0, Acc: 1.0\n",
      "\n",
      "Subject:  17\n",
      "Epoch [1/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [11/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [21/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [31/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [41/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [51/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [61/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [71/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [81/100], Loss: 0.0, Acc: 1.0\n",
      "Epoch [91/100], Loss: 0.0, Acc: 1.0\n",
      "Evaluating model...\n",
      "Loss: 0.0, Acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Batch sizes\n",
    "train_batch_size = 25\n",
    "test_batch_size = 5\n",
    "\n",
    "# Learning Rate\n",
    "learning_rate = 5e-3\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Number of Epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# models = [] # save models at all/ directly?\n",
    "y_preds = []\n",
    "y_truths = []\n",
    "histories = []\n",
    "confusion_matrices = []\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "\n",
    "for _ in subject_id_list:\n",
    "    print('\\nSubject: ', _)\n",
    "    model = StressNet().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_loader, test_loader = get_data_loaders(df, _)\n",
    "    \n",
    "    history = train(model, optimizer, train_loader, test_loader)\n",
    "    histories.append(history)\n",
    "    \n",
    "    y_true, y_pred, test_loss, test_acc = test(model, test_loader)\n",
    "    \n",
    "    test_losses.append(test_loss)\n",
    "    test_accs.append(test_acc)\n",
    "    #confusion_matrices.append(cm)\n",
    "    y_preds.append(y_pred)\n",
    "    y_truths.append(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 1.0\n",
      "Accuracy std: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Mean Accuracy:', np.mean(test_accs))\n",
    "print('Accuracy std:', np.std(test_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    1178\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.title('Testing Accuracies in Leave One Out Cross Validation by Subject Left Out as Testing Data')\n",
    "sns.barplot(x=subject_id_list, y=test_accs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 3))\n",
    "plt.title('Testing Losses in Leave One Out Cross Validation by Subject Left Out as Testing Data')\n",
    "sns.barplot(x=subject_id_list, y=test_losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infodf = pd.read_csv('data/WESAD/readmes.csv', index_col=0)\n",
    "# infodf.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices = [confusion_matrix(y_true, y_pred) \n",
    "                     for y_true, y_pred in zip(y_truths, y_preds)]\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "\n",
    "for i in range(len(confusion_matrices)):\n",
    "    plt.subplot(4,5 ,i+1)\n",
    "    cm = confusion_matrices[i]\n",
    "    \n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cbar=False);\n",
    "    plt.title(f'S{subject_id_list[i]}')\n",
    "    plt.xlabel('Prediction');\n",
    "    plt.ylabel('Ground Truth');\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Stress       1.00      1.00      1.00        76\n",
      "\n",
      "    accuracy                           1.00        76\n",
      "   macro avg       1.00      1.00      1.00        76\n",
      "weighted avg       1.00      1.00      1.00        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['Stress']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'm13_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_true, y_pred, \n",
    "                          target_names=target_names,\n",
    "                          labels=[0, 1])  # Assuming 0=Not-Stress, 1=Stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n  Not-Stress       0.00      0.00      0.00         0\\n      Stress       1.00      1.00      1.00        76\\n\\n    accuracy                           1.00        76\\n   macro avg       0.50      0.50      0.50        76\\nweighted avg       1.00      1.00      1.00        76\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 2 :\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 1, does not match size of target_names, 2. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubject\u001b[39m\u001b[38;5;124m'\u001b[39m, subject_id_list[i], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot-Stress\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStress\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m cr \u001b[38;5;241m=\u001b[39m classification_report(y_true, y_pred, target_names\u001b[38;5;241m=\u001b[39mtarget_names)\n\u001b[1;32m      7\u001b[0m classif_reports\u001b[38;5;241m.\u001b[39mappend(cr)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(cr)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2648\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2642\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2643\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2644\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[1;32m   2645\u001b[0m             )\n\u001b[1;32m   2646\u001b[0m         )\n\u001b[1;32m   2647\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2648\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2649\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2650\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2651\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[1;32m   2652\u001b[0m         )\n\u001b[1;32m   2653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2654\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 1, does not match size of target_names, 2. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "classif_reports = []\n",
    "for i, (y_true, y_pred) in enumerate(zip(y_truths, y_preds)):\n",
    "    print('Subject', subject_id_list[i], ':')\n",
    "    target_names = ['Not-Stress', 'Stress']\n",
    "    cr = classification_report(y_true, y_pred, target_names=target_names)\n",
    "    classif_reports.append(cr)\n",
    "    print(cr)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 2 :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not-Stress       0.00      0.00      0.00         0\n",
      "      Stress       1.00      1.00      1.00        76\n",
      "\n",
      "    accuracy                           1.00        76\n",
      "   macro avg       0.50      0.50      0.50        76\n",
      "weighted avg       1.00      1.00      1.00        76\n",
      "\n",
      "\n",
      "Subject 3 :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not-Stress       0.00      0.00      0.00         0\n",
      "      Stress       1.00      1.00      1.00        77\n",
      "\n",
      "    accuracy                           1.00        77\n",
      "   macro avg       0.50      0.50      0.50        77\n",
      "weighted avg       1.00      1.00      1.00        77\n",
      "\n",
      "\n",
      "Subject 4 :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not-Stress       0.00      0.00      0.00         0\n",
      "      Stress       1.00      1.00      1.00        76\n",
      "\n",
      "    accuracy                           1.00        76\n",
      "   macro avg       0.50      0.50      0.50        76\n",
      "weighted avg       1.00      1.00      1.00        76\n",
      "\n",
      "\n",
      "Subject 5 :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not-Stress       0.00      0.00      0.00         0\n",
      "      Stress       1.00      1.00      1.00        79\n",
      "\n",
      "    accuracy                           1.00        79\n",
      "   macro avg       0.50      0.50      0.50        79\n",
      "weighted avg       1.00      1.00      1.00        79\n",
      "\n",
      "\n",
      "Subject 6 :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not-Stress       0.00      0.00      0.00         0\n",
      "      Stress       1.00      1.00      1.00        78\n",
      "\n",
      "    accuracy                           1.00        78\n",
      "   macro avg       0.50      0.50      0.50        78\n",
      "weighted avg       1.00      1.00      1.00        78\n",
      "\n",
      "\n",
      "Subject 7 :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not-Stress       0.00      0.00      0.00         0\n",
      "      Stress       1.00      1.00      1.00        78\n",
      "\n",
      "    accuracy                           1.00        78\n",
      "   macro avg       0.50      0.50      0.50        78\n",
      "weighted avg       1.00      1.00      1.00        78\n",
      "\n",
      "\n",
      "Subject 8 :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not-Stress       0.00      0.00      0.00         0\n",
      "      Stress       1.00      1.00      1.00        79\n",
      "\n",
      "    accuracy                           1.00        79\n",
      "   macro avg       0.50      0.50      0.50        79\n",
      "weighted avg       1.00      1.00      1.00        79\n",
      "\n",
      "\n",
      "Subject 9 :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not-Stress       0.00      0.00      0.00         0\n",
      "      Stress       1.00      1.00      1.00        78\n",
      "\n",
      "    accuracy                           1.00        78\n",
      "   macro avg       0.50      0.50      0.50        78\n",
      "weighted avg       1.00      1.00      1.00        78\n",
      "\n",
      "\n",
      "Subject 10 :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not-Stress       0.00      0.00      0.00         0\n",
      "      Stress       1.00      1.00      1.00        81\n",
      "\n",
      "    accuracy                           1.00        81\n",
      "   macro avg       0.50      0.50      0.50        81\n",
      "weighted avg       1.00      1.00      1.00        81\n",
      "\n",
      "\n",
      "Subject 11 :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not-Stress       0.00      0.00      0.00         0\n",
      "      Stress       1.00      1.00      1.00        79\n",
      "\n",
      "    accuracy                           1.00        79\n",
      "   macro avg       0.50      0.50      0.50        79\n",
      "weighted avg       1.00      1.00      1.00        79\n",
      "\n",
      "\n",
      "Subject 13 :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not-Stress       0.00      0.00      0.00         0\n",
      "      Stress       1.00      1.00      1.00        79\n",
      "\n",
      "    accuracy                           1.00        79\n",
      "   macro avg       0.50      0.50      0.50        79\n",
      "weighted avg       1.00      1.00      1.00        79\n",
      "\n",
      "\n",
      "Subject 14 :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not-Stress       0.00      0.00      0.00         0\n",
      "      Stress       1.00      1.00      1.00        79\n",
      "\n",
      "    accuracy                           1.00        79\n",
      "   macro avg       0.50      0.50      0.50        79\n",
      "weighted avg       1.00      1.00      1.00        79\n",
      "\n",
      "\n",
      "Subject 15 :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not-Stress       0.00      0.00      0.00         0\n",
      "      Stress       1.00      1.00      1.00        79\n",
      "\n",
      "    accuracy                           1.00        79\n",
      "   macro avg       0.50      0.50      0.50        79\n",
      "weighted avg       1.00      1.00      1.00        79\n",
      "\n",
      "\n",
      "Subject 16 :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not-Stress       0.00      0.00      0.00         0\n",
      "      Stress       1.00      1.00      1.00        79\n",
      "\n",
      "    accuracy                           1.00        79\n",
      "   macro avg       0.50      0.50      0.50        79\n",
      "weighted avg       1.00      1.00      1.00        79\n",
      "\n",
      "\n",
      "Subject 17 :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not-Stress       0.00      0.00      0.00         0\n",
      "      Stress       1.00      1.00      1.00        81\n",
      "\n",
      "    accuracy                           1.00        81\n",
      "   macro avg       0.50      0.50      0.50        81\n",
      "weighted avg       1.00      1.00      1.00        81\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "classif_reports = []\n",
    "for i, (y_true, y_pred) in enumerate(zip(y_truths, y_preds)):\n",
    "    print('Subject', subject_id_list[i], ':')\n",
    "    target_names = ['Not-Stress', 'Stress']\n",
    "    \n",
    "    # Get unique classes present in both true labels and predictions\n",
    "    unique_classes = np.unique(np.concatenate([y_true, y_pred]))\n",
    "    \n",
    "    # Use labels parameter to explicitly specify which labels to include in report\n",
    "    # This handles cases where not all classes are present\n",
    "    try:\n",
    "        cr = classification_report(y_true, y_pred, \n",
    "                                  target_names=target_names,\n",
    "                                  labels=range(len(target_names)),  # Include all possible labels\n",
    "                                  zero_division=0)  # Handle division by zero for missing classes\n",
    "        classif_reports.append(cr)\n",
    "        print(cr)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating report: {e}\")\n",
    "        # Create a simple report for the special case\n",
    "        if len(unique_classes) == 1:\n",
    "            class_idx = unique_classes[0]\n",
    "            class_name = target_names[class_idx]\n",
    "            print(f\"Only one class present: {class_name} (support: {len(y_true)})\")\n",
    "            classif_reports.append(f\"Only class {class_name}, accuracy: 1.00, support: {len(y_true)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = [ float(cr.split('\\n')[3].strip().split('      ')[3]) for cr in classif_reports]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(f1_scores))\n",
    "print(np.std(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
